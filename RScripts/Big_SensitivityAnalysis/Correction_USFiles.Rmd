---
title: "Correction_US_files"
author: "Fabienne RÃ¶ssler"
date: '2023-07-13'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning = FALSE}
source("../DLCAnalyzer_Functions_v4.R")
source("../UnsupervisedAnalysis_Functions.R")
library(sp)         #tested with v1.3-2
library(imputeTS)   #tested with v2.7
library(ggplot2)    #tested with v3.1.0
library(ggmap)      #tested with v3.0.0
library(data.table) #tested with v1.12.8
library(cowplot)    #tested with v0.9.4
library(corrplot)   #tested with v0.84
library(keras)      #REQUIRES TENSORFLOW INSTALL. tested with v2.2.5.0
library(readr)
library(tidyr)
library(biganalytics)
library(M3C)
library(stringr)
library(reticulate)
set.seed(123)
```

# Apply kmeans cluster classifiers (k = 10, 50, 100) to all datasets (CSI, AS, Yohimbine, DREADD, CRS)

Process all files using the corresponding cluster classifier:

```{r, eval = FALSE}
model_classifier <- load_model_hdf5("../../rearing_classifier/Rearing_Classifier.rds")
model_classifier_para <-  readRDS("../../rearing_classifier/Rearing_Classifier_PARAMETERS.Rds")

model_kmeans10 <- load_model_hdf5("../../kmeans_classifiers/kmeans.10.model.hdf5")
model_kmeans10_para <- readRDS("../../kmeans_classifiers/kmeans.10.model.PARAMETERS.rds")
model_kmeans50 <- load_model_hdf5("../../kmeans_classifiers/kmeans.50.model.hdf5")
model_kmeans50_para <- readRDS("../../kmeans_classifiers/kmeans.50.model.PARAMETERS.rds")
model_kmeans100 <- load_model_hdf5("../../kmeans_classifiers/kmeans.100.model.hdf5")
model_kmeans100_para <- readRDS("../../kmeans_classifiers/kmeans.100.model.PARAMETERS.rds")

pipeline <- function(path){
  Tracking <- ReadDLCDataFromCSV(path, fps = 25)
  Tracking$data$centre <- NULL
  Tracking <- CutTrackingData(Tracking,start = 300,end = 300)
  Tracking <- CalibrateTrackingData(Tracking, "area",in.metric = 42*42, c("tr","tl","bl","br"))
  Tracking <- AddOFTZones(Tracking)
  Tracking <- CleanTrackingData(Tracking, likelihoodcutoff = 0.95, existence.pol = ScalePolygon(Tracking$zones$arena,1.3))
  Tracking <- CalculateAccelerations(Tracking)
  Tracking <- CreateSkeletonData_OFT_v4(Tracking)
  Tracking <- ZscoreNormalizeFeatures(Tracking,omit =names(Tracking$features)[c(1:23)],type = "mean")
  Tracking$features <- ScaleFeatures(Tracking$features, select = names(Tracking$features)[1:11], factor = 4)
  Tracking$features <- ScaleFeatures(Tracking$features, select = names(Tracking$features)[20:23], factor = 0.1)
  
  Tracking <- ClassifyBehaviors(Tracking, model_classifier, model_classifier_para)
  Tracking <- OFTAnalysis(Tracking, points = "bodycentre" ,movement_cutoff = 5, integration_period = 5)
  Tracking$labels$rear.classifier <- Tracking$labels$classifications
  
  Tracking <- ClassifyBehaviors(Tracking, model_kmeans10, model_kmeans10_para)
  Tracking$labels$kmeans.10 <- Tracking$labels$classifications
  Tracking <- ClassifyBehaviors(Tracking, model_kmeans50, model_kmeans50_para)
  Tracking$labels$kmeans.50 <- Tracking$labels$classifications
  Tracking <- ClassifyBehaviors(Tracking, model_kmeans100, model_kmeans100_para)
  Tracking$labels$kmeans.100 <- Tracking$labels$classifications
  
  Tracking$labels$classifications <- NULL
  Tracking$train_x <- NULL
  return(Tracking)
}


pipeline_DREADD <- function(path){
  Tracking <- ReadDLCDataFromCSV(path, fps = 25)
  Tracking$data$centre <- NULL
  Tracking <- CutTrackingData(Tracking,start = 300,end = 15000)
  Tracking <- CalibrateTrackingData(Tracking, "area",in.metric = 42*42, c("tr","tl","bl","br"))
  Tracking <- AddOFTZones(Tracking)
  Tracking <- CleanTrackingData(Tracking, likelihoodcutoff = 0.95, existence.pol = ScalePolygon(Tracking$zones$arena,1.3))
  Tracking <- CalculateAccelerations(Tracking)
  Tracking <- CreateSkeletonData_OFT_v4(Tracking)
  Tracking <- ZscoreNormalizeFeatures(Tracking,omit =names(Tracking$features)[c(1:23)],type = "mean")
  Tracking$features <- ScaleFeatures(Tracking$features, select = names(Tracking$features)[1:11], factor = 4)
  Tracking$features <- ScaleFeatures(Tracking$features, select = names(Tracking$features)[20:23], factor = 0.1)
  
  Tracking <- ClassifyBehaviors(Tracking, model_classifier, model_classifier_para)
  Tracking <- OFTAnalysis(Tracking, points = "bodycentre" ,movement_cutoff = 5, integration_period = 5)
  Tracking$labels$rear.classifier <- Tracking$labels$classifications
  
  Tracking <- ClassifyBehaviors(Tracking, model_kmeans10, model_kmeans10_para)
  Tracking$labels$kmeans.10 <- Tracking$labels$classifications
  Tracking <- ClassifyBehaviors(Tracking, model_kmeans50, model_kmeans50_para)
  Tracking$labels$kmeans.50 <- Tracking$labels$classifications
  Tracking <- ClassifyBehaviors(Tracking, model_kmeans100, model_kmeans100_para)
  Tracking$labels$kmeans.100 <- Tracking$labels$classifications
  
  Tracking$labels$classifications <- NULL
  Tracking$train_x <- NULL
  return(Tracking)
}


#CSI data
path <- "../../data/CSI_SA/"
files <- grep(pattern = ".csv",list.files(path),value = TRUE)
ts <- RunPipeline(files,path,pipeline)

#FST data
path <- "../../data/AS/"
files <- grep(pattern = ".csv",list.files(path),value = TRUE)
ts <- append(ts,RunPipeline(files,path,pipeline))


#Yohimbine data
path <- "../../data/Yohimbine/"
files <- grep(pattern = ".csv",list.files(path),value = TRUE)
ts <- append(ts,RunPipeline(files,path,pipeline))

#DREADD data
path <- "../../data/DREADD/"
files <- grep(pattern = ".csv",list.files(path),value = TRUE)
ts <- append(ts,RunPipeline(files,path,pipeline_DREADD))

#CRS data
path <- "../../data/CRS/"
files <- grep(pattern = ".csv",list.files(path),value = TRUE)
ts <- append(ts,RunPipeline(files,path,pipeline))



for(i in names(ts)){
  ts[[i]]$train_x <- NULL
}

saveRDS(ts,"../../data/TS_diffKmeansClusterings.rds")
```

Next we use the function LoadFromTrackingObject to create an unsupervised analysis dataobject. We add the metadata that contains the experimental details. We also add the labels for kmeans with 25 clusters. 

```{r, eval = FALSE}
ts <- readRDS("../../data/TS_diffKmeansClusterings.rds")
US <- LoadFromTrackingObject(ts)
meta <- read.table("../../metadata/AllData_25Clusters.csv", sep = ";", header = T)
rownames(meta) <- meta$DLCFile
meta$DLCFile <- NULL

US <- AddMetaData(US, meta)

ts2 <- readRDS("../../data/TS_AllData_25Clusters.rds")

US <- AddFromTrackingObject(US, ts2)

saveRDS(US,"../../data/US_AllData_v2.rds")
```

# Pre-processing the data

We load the data for the unsupervised analysis object.

```{r}
US <- readRDS("../../data/US_AllData_v2.rds")
```

We first smooth the data over 5 frames, this removes clusters that were identified in a single frame and ensures that behavior trains are better resolved.

```{r, eval = FALSE}
US <- SmoothLabels_US(US, 5)
```

We calculate metrics, such as number of onset-offset and number of frames for each cluster.

```{r, eval = FALSE}
US <- CalculateMetrics(US)
```

Next, we calculate the trainsitionsmatrix for each clustering analysis in each file

```{r, eval = FALSE}
US <- AddTransitionMatrixData(US)
```

We save this object, so next time we do not have to re-process it

```{r, eval = FALSE}
saveRDS(US,"../../data/US_AllData_v2.rds")
```

